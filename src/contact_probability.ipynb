{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# usage: python3 contact_probability.py #MODEL(AA or CA) #PDB_BASE #XTC_FILE \\\n",
    "# #file.cont_FILE #OUTPUT\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import mdtraj as md\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_r_initial(contacts, model=\"AA\"):\n",
    "    \"\"\"\n",
    "    Function to evaluate initial pairwise distances accordingly the model \\\n",
    "    simulated.\n",
    "    Input:\n",
    "     contacts_list - Array with the definitions from pairs section of the \\\n",
    "     forcefield (TPR file.)\n",
    "     model - AA = All-Atom; CA = Carbon_alpha Coarse-Grained\n",
    "    Output:\n",
    "     r_initial - vector with the initial distance of each pair.\n",
    "    \"\"\"\n",
    "    if model == \"CA\":\n",
    "        r_initial = np.power(np.divide(np.multiply(contacts[:, 4], 1.2), \\\n",
    "                                                   contacts[:, 3]), \\\n",
    "                             np.divide(1, 2))\n",
    "    elif model == \"AA\":\n",
    "        r_initial = np.power(np.divide(np.multiply(contacts[:, 4], 2), \\\n",
    "                                                   contacts[:, 3]),\\\n",
    "                             np.divide(1, 6))\n",
    "    else:\n",
    "        print(\"You have not provided an unimplemented model.\")\n",
    "        exit()\n",
    "    return r_initial\n",
    "\n",
    "\n",
    "def fromlistto1d(inputlist):\n",
    "    \"\"\"\n",
    "    Function to change the input (a list, an array or a sequence) in a column \\\n",
    "    vector.\n",
    "    \"\"\"\n",
    "    inputlist = np.asarray(inputlist)\n",
    "    return inputlist.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "def gen_contact_probability(pdb_file, xtc_file, pairs_indexes, r_initial, \\\n",
    "                            threshold=1.5, chunk=10000):\n",
    "    \"\"\"\n",
    "    Function to evaluate the contact probability per residue.\n",
    "    Input:\n",
    "     pdb_file - File with your structure (PDB or GRO files for instance).\n",
    "     xtc_file - Trajectory.\n",
    "     pairs_indexes - Numpy array Nx2 with the pairs to be used to evaluate \\\n",
    "     the contacts. (The first two columns of the pairs section in the TPR file \\\n",
    "     without the header).\n",
    "     r_initial - Initial distance for each given pair to be used as a reference.\n",
    "     threshold - Value to be used as a threshold to evaluate the contacts.\n",
    "     chunk - Size of each chunk in which the trajectory will be analyzed.\n",
    "    Output:\n",
    "     p_q_i - QxN numpy array with the contact probability at each given total \\\n",
    "     contacts value for each atom/residue.\n",
    "     contacs_list - numpy 1-D (Q) array with the number of contacts.\n",
    "     atoms_list - numpy 1-D (N) array with the atoms/residues involved.\n",
    "    \"\"\"\n",
    "\n",
    "    cutoff = np.multiply(r_initial, threshold)\n",
    "\n",
    "    # Correcting the numbering of atoms/residues involved.\n",
    "    atoms_indexes = np.unique(pairs_indexes)\n",
    "    atoms_involved = np.add(atoms_indexes, 1)\n",
    "\n",
    "    # Correcting the contacts value and its correspondent index.\n",
    "    contacts_indexes = np.arange(np.shape(pairs_indexes)[0] + 1)\n",
    "\n",
    "    # Initializing the contacts involved. Is expected the total number of \\\n",
    "    # contacts is formed at least in the first frame.\n",
    "    contacts_involved = np.asarray([np.shape(pairs_indexes)[0]])\n",
    "\n",
    "    # Initializing the results array\n",
    "    results = np.zeros((np.shape(contacts_indexes)[0], np.shape(r_initial)[0]))\n",
    "\n",
    "    # The last number of frames will store the total number for sanity check.\n",
    "    n_frames = np.zeros(np.shape(contacts_indexes)[0] + 1)\n",
    "    for chunk_trajectory in md.iterload(xtc_file, top=pdb_file, chunk=chunk):\n",
    "        trajectory = md.compute_distances(chunk_trajectory, pairs_indexes)\n",
    "        print(chunk_trajectory)\n",
    "        # Getting the number of frames of each chunk and adding to the total\n",
    "        n_frames[-1] += np.shape(trajectory)[0]\n",
    "        below_threshold = np.less_equal(trajectory, cutoff)\n",
    "        # Generate a matrix with 1 where contacts are formed.\n",
    "        num_below_threshold = np.multiply(below_threshold, 1)\n",
    "        # (number of contact per timestep)\n",
    "        contacts_time = np.sum(num_below_threshold, axis=1)\n",
    "        # Evaluating the contacts formed.\n",
    "        contacts_involved = np.unique(np.concatenate((contacts_time, \\\n",
    "                                                      contacts_involved)))\n",
    "        # Iterating over the number of contacts found.\n",
    "        # n_frames receive number of frames found with Q contacts\n",
    "        for i in contacts_indexes:\n",
    "            idx = np.equal(contacts_time, i)\n",
    "            n_frames[i] += idx.sum()\n",
    "            results[i] += np.sum(num_below_threshold[idx], axis=0)\n",
    "\n",
    "    # To normalize all the probabilities in each dimension after all pieces are\\\n",
    "    # read.\n",
    "    for i in contacts_involved:\n",
    "        results[i] = np.nan_to_num(np.divide(results[i], n_frames[i]))\n",
    "\n",
    "    # Extracting nonzero results\n",
    "    results_nz = results[contacts_involved]\n",
    "\n",
    "    # Checking if all individual probabilities are normalized.\n",
    "    assert np.less_equal(np.max(results_nz), 1)\n",
    "\n",
    "    # Initiaizing the P(Q,i)\n",
    "    p_q_i = np.zeros((np.shape(contacts_involved)[0], \\\n",
    "                        np.shape(atoms_involved)[0]))\n",
    "    # The probability for each atom is given multiplying the probability of all\\\n",
    "    # pairs with this atom.\n",
    "    for i, atom in enumerate(atoms_indexes):\n",
    "        idx_atom = np.isin(pairs_indexes, atom).any(axis=1)\n",
    "        p_q_i[:, i] += np.sum(results_nz[:, idx_atom], axis=1)\n",
    "        # normalization over the number of contacts with each given atom/residue\n",
    "        p_q_i[:, i] = np.nan_to_num(np.divide(p_q_i[:, i], idx_atom.sum()))\n",
    "    # Sanity check of number of frames read\n",
    "    assert np.less_equal(np.sum(n_frames[:-1]), n_frames[-1])\n",
    "\n",
    "    return p_q_i, contacts_involved, atoms_involved\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    pairs_contacts = sys.argv[4]\n",
    "\n",
    "    contacts = np.genfromtxt(pairs_contacts)\n",
    "\n",
    "    # This MUST be done due to python indexes, that starts from zero\n",
    "    pairs_indexes = np.subtract(contacts[:, 0:2], 1)\n",
    "\n",
    "    r_initial = evaluate_r_initial(contacts, model=str(sys.argv[1]))\n",
    "\n",
    "    raw_prob, contacts, atoms = \\\n",
    "    gen_contact_probability(sys.argv[2], sys.argv[3], pairs_indexes, r_initial)\n",
    "\n",
    "    np.savetxt(\"raw-\" + str(sys.argv[5]), raw_prob)\n",
    "\n",
    "    np.savetxt(\"Q-involved-\"+ str(sys.argv[5]), contacts,\n",
    "               newline=\"\\n\", header=\"# contacts involved\", fmt=\"%d\")\n",
    "\n",
    "    np.savetxt(\"atoms-involved-\"+ str(sys.argv[5]), atoms, \\\n",
    "               newline=\"\\n\", header=\"# atoms involved\", fmt=\"%d\")\n",
    "\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
