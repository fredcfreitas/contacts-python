{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c09081",
   "metadata": {},
   "source": [
    "### This code calculate the contact probability using mdtraj and numpy libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0cfa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# usage: python3 contact_probability.py #MODEL(AA or CA) #PDB_BASE #XTC_FILE \\\n",
    "# #file.cont_FILE #OUTPUT\n",
    "#\n",
    "# #file.cont_FILE is the pairs section extracted from SMOG *.top file\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import mdtraj as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_r_initial(contacts, model=\"AA\"):\n",
    "    \"\"\"\n",
    "    Function to evaluate initial pairwise distances found in the initial model.\n",
    "    Input:\n",
    "     contacts_list - Array with the definitions from pairs section of the \\\n",
    "     forcefield (SMOG TOP file.)\n",
    "     model - AA = All-Atom; CA = Carbon_alpha Coarse-Grained\n",
    "    Output:\n",
    "     r_initial - vector with the initial distances of each pair.\n",
    "    \"\"\"\n",
    "    if model == \"CA\":\n",
    "        r_initial = np.power(\n",
    "            np.divide(np.multiply(contacts[:, 4], 1.2), contacts[:, 3]), \\\n",
    "                np.divide(1, 2)\n",
    "        )\n",
    "    elif model == \"AA\":\n",
    "        r_initial = np.power(\n",
    "            np.divide(np.multiply(contacts[:, 4], 2), contacts[:, 3]), \\\n",
    "                np.divide(1, 6)\n",
    "        )\n",
    "    else:\n",
    "        print(\"You have not provided a recognizable model.\")\n",
    "        sys.exit()\n",
    "    return r_initial\n",
    "\n",
    "\n",
    "def fromlistto1d(inputlist):\n",
    "    \"\"\"\n",
    "    Function to change the input (a list, an array or a sequence) into a \\\n",
    "    column vector.\n",
    "    \"\"\"\n",
    "    inputlist = np.asarray(inputlist)\n",
    "    return inputlist.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def gen_contact_probability(\n",
    "    pdb_file, xtc_file, pairs_indexes, r_initial, threshold=1.5, chunk=10000\\\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Function to evaluate the contact probability per atom/residue.\n",
    "    Input:\n",
    "     pdb_file - File with your structure (PDB or GRO file).\n",
    "     xtc_file - Trajectory.\n",
    "     pairs_indexes - Numpy array Nx2 with the pairs to be used to evaluate \\\n",
    "      the contacts. (The first two columns of the pairs section in the TOP \\\n",
    "      file without the header and corrected to python indexation).\n",
    "     r_initial - Initial distance for each given pair.\n",
    "     threshold - Value to be used as a threshold to evaluate the contacts.\n",
    "     chunk - Size of each chunk in which the trajectory will be analyzed.\n",
    "    Output:\n",
    "     p_q_i - QxN numpy array with the contact probability at each given total \\\n",
    "      contacts value for each atom/residue.\n",
    "     contacts_list - numpy 1-D (Q) array with the number of contacts.\n",
    "     atoms_list - numpy 1-D (N) array with the atoms/residues involved.\n",
    "    \"\"\"\n",
    "    # Calculating the cutoff distances for each pair\n",
    "    cutoff = np.multiply(r_initial, threshold)\n",
    "    # Correcting the  atoms/residue numbering.\n",
    "    atoms_indexes = np.unique(pairs_indexes)\n",
    "    atoms_involved = np.add(atoms_indexes, 1)\n",
    "    # Correcting the contact index to start from 1.\n",
    "    contacts_indexes = np.arange(np.shape(pairs_indexes)[0] + 1)\n",
    "    # Initializing the contacts involved. Is expected the total number of \\\n",
    "    # contacts is formed at least in the first frame.\n",
    "    contacts_involved = np.asarray([np.shape(pairs_indexes)[0]])\n",
    "    # Initializing the results array\n",
    "    results = np.zeros((np.shape(contacts_indexes)[0], np.shape(r_initial)[0]))\n",
    "    # n_frames will store the total number of frames read as a sanity check.\n",
    "    n_frames = np.zeros(np.shape(contacts_indexes)[0] + 1)\n",
    "    for chunk_trajectory in md.iterload(xtc_file, top=pdb_file, chunk=chunk):\n",
    "        trajectory = md.compute_distances(chunk_trajectory, pairs_indexes)\n",
    "        print(chunk_trajectory)\n",
    "        # Getting the number of frames of each chunk and adding to the total\n",
    "        n_frames[-1] += np.shape(trajectory)[0]\n",
    "        below_threshold = np.less_equal(trajectory, cutoff)\n",
    "        # Generate a matrix with 1 where contacts are formed.\n",
    "        num_below_threshold = np.multiply(below_threshold, 1)\n",
    "        # (number of contact per timestep)\n",
    "        contacts_time = np.sum(num_below_threshold, axis=1)\n",
    "        # Adding the number of contacts evaluated to the list of previous \\\n",
    "        # number of formed contacts list.\n",
    "        contacts_involved = np.unique(\n",
    "            np.concatenate((contacts_time, contacts_involved))\n",
    "        )\n",
    "        # Iterating over the number of contacts found.\n",
    "        # n_frames receive number of frames found with Q contacts\n",
    "        for i in contacts_indexes:\n",
    "            idx = np.equal(contacts_time, i)\n",
    "            n_frames[i] += idx.sum()\n",
    "            results[i] += np.sum(num_below_threshold[idx], axis=0)\n",
    "    # To normalize all the probabilities in each dimension after all pieces \\\n",
    "    # are read.\n",
    "    for i in contacts_involved:\n",
    "        results[i] = np.nan_to_num(np.divide(results[i], n_frames[i]))\n",
    "    # Extracting nonzero results\n",
    "    results_nz = results[contacts_involved]\n",
    "    # Checking if all individual probabilities are normalized.\n",
    "    assert np.less_equal(np.max(results_nz), 1)\n",
    "    # Initializing the P(Q,i)\n",
    "    p_q_i = np.zeros((np.shape(contacts_involved)[0], \\\n",
    "                      np.shape(atoms_involved)[0]))\n",
    "    # The probability for each atom is given multiplying the probability of \\\n",
    "    # all pairs with this atom.\n",
    "    for i, atom in enumerate(atoms_indexes):\n",
    "        idx_atom = np.isin(pairs_indexes, atom).any(axis=1)\n",
    "        p_q_i[:, i] += np.sum(results_nz[:, idx_atom], axis=1)\n",
    "        # normalization over the number of contacts with each given \\\n",
    "        # atom/residue\n",
    "        p_q_i[:, i] = np.nan_to_num(np.divide(p_q_i[:, i], idx_atom.sum()))\n",
    "    # Sanity check of number of frames read\n",
    "    assert np.less_equal(np.sum(n_frames[:-1]), n_frames[-1])\n",
    "    return p_q_i, contacts_involved, atoms_involved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85efd44",
   "metadata": {},
   "source": [
    "#### Here starts the main part. Be sure to use the right files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e70069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Starting the main function. Take a look at the comments on top regarding \\\n",
    "    input files.\n",
    "    \"\"\"\n",
    "    pairs_contacts = sys.argv[4]\n",
    "    # comments are inserted to avoid problems with common file header\n",
    "    contacts = np.loadtxt(pairs_contacts, comments=['#', '[', ';'])\n",
    "    # This MUST be done due to python indexes, that starts from zero\n",
    "    pairs_indexes = np.subtract(contacts[:, 0:2], 1)\n",
    "    # Getting distances from TOP file (from original structure)\n",
    "    r_initial = evaluate_r_initial(contacts, model=str(sys.argv[1]))\n",
    "    # Calling the contact probability function\n",
    "    raw_prob, contacts, atoms = gen_contact_probability(\n",
    "        sys.argv[2], sys.argv[3], pairs_indexes, r_initial\n",
    "    )\n",
    "    # Saving the contact probability array\n",
    "    np.savetxt(\"raw-\" + str(sys.argv[5]), raw_prob)\n",
    "    # Saving the list of contacts.\n",
    "    np.savetxt(\n",
    "        \"Q-involved-\" + str(sys.argv[5]),\n",
    "        contacts,\n",
    "        newline=\"\\n\",\n",
    "        header=\"# contacts involved\",\n",
    "        fmt=\"%d\"\n",
    "    )\n",
    "    # Saving the list of atoms/residues involved\n",
    "    np.savetxt(\n",
    "        \"atoms-involved-\" + str(sys.argv[5]),\n",
    "        atoms,\n",
    "        newline=\"\\n\",\n",
    "        header=\"# atoms involved\",\n",
    "        fmt=\"%d\"\n",
    "    )\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c53d7",
   "metadata": {},
   "source": [
    "Uncomment the first lines below with the 'sys.argv' to run the notebook\n",
    " instead of the script.\n",
    " Do not forget to properly replace the options. Example to run the notebook\n",
    " with shared files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b591312",
   "metadata": {},
   "source": [
    "`sys.argv = \"contact_probability.py AA ../share/ci2-AA-120-run.gro ../share/ci2-AA-120-run.xtc ../share/ci2-AA-contacts.dat output\".split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.argv = \"contact_probability.py #MODEL(AA or CA) #PDB_BASE #XTC_FILE #file.cont_FILE #OUTPUT\".split()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
